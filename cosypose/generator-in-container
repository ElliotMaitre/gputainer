#!/bin/bash

. ./env.sh

if [ -z "${MYHOME}" ]; then
    echo "This script must be started by apptainer"
    echo "  ./2-initial-submitter"
    exit 1
fi

echo I am in a container:
env|grep APPTAINER

id=genlauncher-${SLURM_JOBID-deleteme}

# creating scripts for some number of complex tasks

for task_number in 1; do

    echo I am preparing a complex task number ${task_number}
    
    # Plan something here (using OpenGL/EGL like with pyBullet)
    # then generate slurm sbatch file
    # Example:
    cat << EOF > ${header}-${id}-${task_number}

. ./environment.sh
cd custom_training

export MKL_NUM_THREADS=1
export OMP_NUM_THREADS=1

python -m custom_training.run_detector_training --config custom
EOF

    # make this script executable
    chmod +x ${header}-${id}-${task_number}

    # now we want to run it with SLURM inside a gputainer container

    # The following file is the slurm+container launcher for the above file

    # Now generate slurm sbatch file.
    cat << EOF > ${header}-${id}-${task_number}.sbatch.temp
#!/bin/bash
#SBATCH --job-name=CosyposeDetectorTraining-${task_number}
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --partition=gpu
#SBATCH --mail-type=ALL
#SBATCH --output=stdout-%j.txt
#SBATCH --error=stderr-%j.txt
#SBATCH --mem=30G
#SBATCH --gres=gpu:1

# From inside the container run by slurm, start
# the script generated above
../__gputainer/runvnc $(pwd)/${header}-${id}-${task_number}
EOF
    # Make it appear at once by renaming it to the right name.
    # This file name is tracked by the watcher
    # from inside ./2-initial-submitter
    # and will be submitted to SLURM
    mv ${header}-${id}-${task_number}.sbatch.temp  ${header}-${id}-${task_number}.sbatch

done

for task_number in 2; do

    echo I am preparing a complex task number ${task_number}
    
    # Plan something here (using OpenGL/EGL like with pyBullet)
    # then generate slurm sbatch file
    # Example:
    cat << EOF > ${header}-${id}-${task_number}

. ./environment.sh
cd custom_training


export MKL_NUM_THREADS=1
export OMP_NUM_THREADS=1

python -m custom_training.run_pose_training --config custom-coarse
EOF

    # make this script executable
    chmod +x ${header}-${id}-${task_number}

    # now we want to run it with SLURM inside a gputainer container

    # The following file is the slurm+container launcher for the above file

    # Now generate slurm sbatch file.
    cat << EOF > ${header}-${id}-${task_number}.sbatch.temp
#!/bin/bash
#SBATCH --job-name=CosyposePoseCoarse-${task_number}
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --partition=gpu
#SBATCH --mail-type=ALL
#SBATCH --output=stdout-%j.txt
#SBATCH --error=stderr-%j.txt
#SBATCH --mem=30G
#SBATCH --gres=gpu:1

# From inside the container run by slurm, start
# the script generated above
../__gputainer/runvnc $(pwd)/${header}-${id}-${task_number}
EOF
    # Make it appear at once by renaming it to the right name.
    # This file name is tracked by the watcher
    # from inside ./2-initial-submitter
    # and will be submitted to SLURM
    mv ${header}-${id}-${task_number}.sbatch.temp  ${header}-${id}-${task_number}.sbatch

done

for task_number in 3; do

    echo I am preparing a complex task number ${task_number}
    
    # Plan something here (using OpenGL/EGL like with pyBullet)
    # then generate slurm sbatch file
    # Example:
    cat << EOF > ${header}-${id}-${task_number}

. ./environment.sh
cd custom_training

export MKL_NUM_THREADS=1
export OMP_NUM_THREADS=1

python -m custom_training.run_pose_training --config custom-refiner
EOF

    # make this script executable
    chmod +x ${header}-${id}-${task_number}

    # now we want to run it with SLURM inside a gputainer container

    # The following file is the slurm+container launcher for the above file

    # Now generate slurm sbatch file.
    cat << EOF > ${header}-${id}-${task_number}.sbatch.temp
#!/bin/bash
#SBATCH --job-name=CosyposePoseRefiner-${task_number}
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --partition=gpu
#SBATCH --mail-type=ALL
#SBATCH --output=stdout-%j.txt
#SBATCH --error=stderr-%j.txt
#SBATCH --mem=30G
#SBATCH --gres=gpu:1

# From inside the container run by slurm, start
# the script generated above
../__gputainer/runvnc $(pwd)/${header}-${id}-${task_number}
EOF
    # Make it appear at once by renaming it to the right name.
    # This file name is tracked by the watcher
    # from inside ./2-initial-submitter
    # and will be submitted to SLURM
    mv ${header}-${id}-${task_number}.sbatch.temp  ${header}-${id}-${task_number}.sbatch

done
