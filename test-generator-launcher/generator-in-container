#!/bin/bash

. ./env.sh

if [ -z "${MYHOME}" ]; then
    echo "This script must be started by apptainer"
    echo "  ./2-initial-submitter"
    exit 1
fi

echo I am in a container:
env|grep APPTAINER

id=genlauncher-${SLURM_JOBID-deleteme}

# creating scripts for some number of complex tasks

for task_number in 1 2; do

    echo I am preparing a complex task number ${task_number}
    
    # Plan something here (using OpenGL/EGL like with pyBullet)
    # then generate slurm sbatch file
    # Example:
    cat << EOF > ${header}-${id}-${task_number}

echo I am a fake complex task called ${header}-${id}-${task_number}
echo I am generated at date $(date) and started at date \$(date)
echo I am running on host \$(hostname)
echo and I should be runned from inside a container
hostname
nvidia-smi
env | grep APPTAINER
EOF

    # make this script executable
    chmod +x ${header}-${id}-${task_number}

    # now we want to run it with SLURM inside a gputainer container

    # The following file is the slurm+container launcher for the above file

    # Now generate slurm sbatch file.
    cat << EOF > ${header}-${id}-${task_number}.sbatch.temp
#!/bin/bash
#SBATCH --job-name=fakeGeneratedTask-${task_number}
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --partition=gpu
#SBATCH --mail-type=ALL
#SBATCH --output=stdout-%j.txt
#SBATCH --error=stderr-%j.txt
#SBATCH --mem=5G
#SBATCH --gres=gpu:1

# From inside the container run by slurm, start
# the script generated above
../__gputainer/runvnc $(pwd)/${header}-${id}-${task_number}
EOF
    # Make it appear at once by renaming it to the right name.
    # This file name is tracked by the watcher
    # from inside ./2-initial-submitter
    # and will be submitted to SLURM
    mv ${header}-${id}-${task_number}.sbatch.temp  ${header}-${id}-${task_number}.sbatch

done
